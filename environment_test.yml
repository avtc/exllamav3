name: exllamav3-p2p-test
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults

dependencies:
  # Python
  - python=3.10
  - pip=23.0.0
  - setuptools=68.0.0
  - wheel=0.40.0

  # Core dependencies
  - torch>=2.6.0
  - flash-attn>=2.7.4.post1
  - tokenizers>=0.21.1
  - numpy>=2.1.0
  - rich
  - typing_extensions
  - safetensors>=0.3.2
  - ninja
  - pillow
  - pyyaml
  - marisa-trie
  - kbnf>=0.4.2
  - pydantic==2.11.0
  - formatron>=0.5.0

  # Testing framework
  - pytest>=7.4.0
  - pytest-cov>=4.1.0
  - pytest-xdist>=3.3.0
  - pytest-benchmark>=4.0.0
  - pytest-mock>=3.11.1
  - pytest-asyncio>=0.21.1

  # Mocking and utilities
  - mock>=5.1.0
  - freezegun>=1.2.2

  # Performance and profiling
  - psutil>=5.9.0
  - memory-profiler>=0.60.0
  - py-spy>=0.3.0

  # CUDA and GPU support
  - cudatoolkit=11.8
  - cudnn=8.6.0.163
  - nccl=2.16.5

  # Development tools
  - black>=23.0.0
  - flake8>=6.0.0
  - mypy>=1.5.0

  # Documentation
  - sphinx>=7.0.0
  - sphinx-rtd-theme>=1.3.0

  # Additional testing utilities
  - coverage[toml]>=7.2.0
  - pre-commit>=3.3.0
  - tox>=4.0.0

  # Optional dependencies for full testing
  - transformers>=4.50.0
  - adjustText>=1.3.0
  - aqlm>=1.1.6
  - autoawq>=0.2.8
  - bitsandbytes>=0.45.4
  - datasets
  - exllamav2>=0.2.8
  - gguf>=0.14.0
  - human_eval==1.0.3
  - matplotlib>=3.10.0
  - vptq>=0.0.5
  - tabulate

  # Install additional packages via pip
  - pip:
      - cupy-cuda11x>=12.0.0  # CUDA 11.x support
      - torch[extra]  # Additional PyTorch features including NCCL
      - --extra-index-url https://download.pytorch.org/whl/cu118